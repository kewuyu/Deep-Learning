{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5347c60f",
   "metadata": {},
   "source": [
    "# 1.数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c14967",
   "metadata": {},
   "source": [
    "## Step1.加载数据集（包含数据预处理） \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7233a73e",
   "metadata": {},
   "source": [
    "### 数据预处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e546a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共找到 41 个 transforms 方法：\n",
      "AugMix\n",
      "AutoAugment\n",
      "AutoAugmentPolicy\n",
      "CenterCrop\n",
      "ColorJitter\n",
      "Compose\n",
      "ConvertImageDtype\n",
      "ElasticTransform\n",
      "FiveCrop\n",
      "GaussianBlur\n",
      "Grayscale\n",
      "InterpolationMode\n",
      "Lambda\n",
      "LinearTransformation\n",
      "Normalize\n",
      "PILToTensor\n",
      "Pad\n",
      "RandAugment\n",
      "RandomAdjustSharpness\n",
      "RandomAffine\n",
      "RandomApply\n",
      "RandomAutocontrast\n",
      "RandomChoice\n",
      "RandomCrop\n",
      "RandomEqualize\n",
      "RandomErasing\n",
      "RandomGrayscale\n",
      "RandomHorizontalFlip\n",
      "RandomInvert\n",
      "RandomOrder\n",
      "RandomPerspective\n",
      "RandomPosterize\n",
      "RandomResizedCrop\n",
      "RandomRotation\n",
      "RandomSolarize\n",
      "RandomVerticalFlip\n",
      "Resize\n",
      "TenCrop\n",
      "ToPILImage\n",
      "ToTensor\n",
      "TrivialAugmentWide\n"
     ]
    }
   ],
   "source": [
    "#数据预处理\n",
    "from torchvision import transforms\n",
    "# 查看定义数据预处理操作\n",
    "import inspect\n",
    "transform_methods = [name for name, obj in inspect.getmembers(transforms)\n",
    "                     if inspect.isclass(obj) or inspect.isfunction(obj)]\n",
    "\n",
    "# 打印结果\n",
    "print(f\"共找到 {len(transform_methods)} 个 transforms 方法：\")\n",
    "for name in sorted(transform_methods):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "614fed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "##用法\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a65236",
   "metadata": {},
   "source": [
    "### 方法一：加载标准数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df6da4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共找到 72 个数据集：\n",
      "CIFAR10\n",
      "CIFAR100\n",
      "CLEVRClassification\n",
      "CREStereo\n",
      "Caltech101\n",
      "Caltech256\n",
      "CarlaStereo\n",
      "CelebA\n",
      "Cityscapes\n",
      "CocoCaptions\n",
      "CocoDetection\n",
      "Country211\n",
      "DTD\n",
      "DatasetFolder\n",
      "EMNIST\n",
      "ETH3DStereo\n",
      "EuroSAT\n",
      "FER2013\n",
      "FGVCAircraft\n",
      "FakeData\n",
      "FallingThingsStereo\n",
      "FashionMNIST\n",
      "Flickr30k\n",
      "Flickr8k\n",
      "Flowers102\n",
      "FlyingChairs\n",
      "FlyingThings3D\n",
      "Food101\n",
      "GTSRB\n",
      "HD1K\n",
      "HMDB51\n",
      "INaturalist\n",
      "ImageFolder\n",
      "ImageNet\n",
      "Imagenette\n",
      "InStereo2k\n",
      "KMNIST\n",
      "Kinetics\n",
      "Kitti\n",
      "Kitti2012Stereo\n",
      "Kitti2015Stereo\n",
      "KittiFlow\n",
      "LFWPairs\n",
      "LFWPeople\n",
      "LSUN\n",
      "LSUNClass\n",
      "MNIST\n",
      "Middlebury2014Stereo\n",
      "MovingMNIST\n",
      "Omniglot\n",
      "OxfordIIITPet\n",
      "PCAM\n",
      "PhotoTour\n",
      "Places365\n",
      "QMNIST\n",
      "RenderedSST2\n",
      "SBDataset\n",
      "SBU\n",
      "SEMEION\n",
      "STL10\n",
      "SUN397\n",
      "SVHN\n",
      "SceneFlowStereo\n",
      "Sintel\n",
      "SintelStereo\n",
      "StanfordCars\n",
      "UCF101\n",
      "USPS\n",
      "VOCDetection\n",
      "VOCSegmentation\n",
      "VisionDataset\n",
      "WIDERFace\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import inspect\n",
    "datasets_classes = [name for name,obj in inspect.getmembers(datasets)if inspect.isclass(obj) and issubclass(obj,datasets.VisionDataset)]\n",
    "print(f\"共找到 {len(datasets_classes)} 个数据集：\")\n",
    "for name in sorted(datasets_classes):\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a175fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:16<00:00, 10641587.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "#用法 \n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2baa3d",
   "metadata": {},
   "source": [
    "### 方法二 加载自定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff15df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np \n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, transforms=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.img_names = os.listdir(img_dir)  # 获取图像文件名\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_names[idx] # idx = 0\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        \n",
    "        label_name = os.path.splitext(img_name)[0] + \".png\"\n",
    "        label_path = os.path.join(self.label_dir, label_name)\n",
    "\n",
    "        # 加载图片和标签\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # 转换为 RGB 图像\n",
    "        label = Image.open(label_path).convert(\"L\")  # 转换为单通道图像\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            label = torch.tensor(np.array(label), dtype=torch.long)  # 转换为张量\n",
    "        \n",
    "        return image, label\n",
    "data = SegmentationDataset(\n",
    "    img_dir='train_and_label/img',\n",
    "    label_dir='train_and_label/label',\n",
    "    transforms=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0478fb33",
   "metadata": {},
   "source": [
    "## Step2.数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92bf1b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8708f3",
   "metadata": {},
   "source": [
    "## Step3.数据集读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f479b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8917d14c",
   "metadata": {},
   "source": [
    "# 2.模型搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752d649c",
   "metadata": {},
   "source": [
    "## 方法一 容器搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474e81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "model = nn.Sequential(nn.Linear(784, 256), nn.ReLU(), nn.Linear(256, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff35e1f",
   "metadata": {},
   "source": [
    "## 方法二 自定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40caf9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "class MLP(Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = MLP(input_size=784, hidden_size=256, output_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9b64cc",
   "metadata": {},
   "source": [
    "# 3.损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeeb2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38043b99",
   "metadata": {},
   "source": [
    "# 4.优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17dc05b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbffe52",
   "metadata": {},
   "source": [
    "# 5.模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb0ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5  # 设置训练的轮数\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_dataloader:        \n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        loss.backward()        # 计算梯度\n",
    "        optimizer.step()       # 更新权重\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 计算准确率\n",
    "        _, predicted = torch.max(outputs, 1)  # 选择最大概率的类别\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
